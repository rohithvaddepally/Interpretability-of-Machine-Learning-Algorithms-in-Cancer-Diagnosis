# ğŸ§  Interpretability of ML Algorithms in Cancer Diagnosis

This repository contains my MSc research on how interpretable and explainable machine learning models can support cancer diagnosis in healthcare.

# ğŸ” Overview

Conducted a systematic literature review across IEEE Xplore, ScienceDirect, and Scopus to evaluate interpretable, explainable, and fair ML models used in oncology.

Summarised findings in a research poster, highlighting key methods like rule-extraction, SHAP, surrogate models, and fuzzy classifiers.

# ğŸ¯ Key Insights

No single model fits all cancer typesâ€”different interpretable techniques work better for breast, colorectal, and lung cancers.

Higher accuracy often leads to lower interpretability, emphasizing the need for balanced ML approaches.

Explainability methods such as SHAP and global surrogate models help clinicians understand model decisions. 


# ğŸ“ Contents

Element 1: Systematic Literature Review

Element 2: Research Poster
